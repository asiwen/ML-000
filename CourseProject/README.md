
题目：Lending Club 数据集模型训练。

根据给定的Lending Club 数据集进行调优。

## 要求
1. 根据三种衍生变量构建打方法每个至少构建出一个衍生变量，并检验其结果。
2. 实现非深度学习至少三个模型并进行集成;
3. 实现至少一种深度学习网络，并比较其效果; 检验是否可以将之进行集成;
4. 根据自己选择的深度学习网络，实现至少一种训练的trick。


## 方案

### 多个lightgbm模型集成
1. 利用 5 k-fold方法划分数据训练不同模型，然后根据投票（ 3 vs. 2, 少数服从多数）来确定最后结果。（助教给的默认方法）__代码见：__ [loan_pred_ml.ipynb](loan_pred_ml.ipynb)
2. 特征工程方面： 将其中discrete_addr_state， discrete_grade两个变量由one-hot改成了target encoder方式， 准确提升到 ``0.91766``（较基准中的`0.91756`高一点点）。 另外在target encoder基础之上删掉了 application_type 变量， 准确率较默认变量有提升，但未超过助教给的基线（0.91752），也许是参数未调好，亦或该特征改变提升不大。
3. 对于lightgbm, 本题中nan填充与否，最终影响不明显。

### 深度学习方式
1. 采用了 带dropout的多层（> 10)全连接网络。 __代码见：__ [loan_pred_dl.ipynb](loan_pred_dl.ipynb)
2. 实验结果：最好的精度在0.8359, 其余大多数在 0.789左右。 

## 小结与后续改进

### 小结
1. 掌握了传统机器学习的训练、特征构建、调参基本方法。 但是正对具体的模型训练与优化还不是很有效，对算法和模型内部原理了解还不深入。 自动超参搜索也有尝试，但多数情况下不如手工的有效。
2. 了解神经网络的原理，网络构建方法以及常见的有用网络模型。 
3. 通过本次作业多层全连接网络中， 调整隐藏层的节点 不如增加层数 对模型的性能提升大; 另外，训练epoch大一点，最终训练的模型性能稳定性略好。
4. 作业中，nn模型的随机性较大（较lightgbm)。

### 作业后续的改进
1. 衍生变量构造上还不太充分，可结合一些借贷业务进行创建。
2. 模型集成上可以尝试 xgboost, catboost等。
3. 神经网络方面， 特征的学习上面还有待加强。Embadding还不知道如何应用到该问题中。
4. 试试用TabNet网络。
5. 通过神经网络将 xgboost, lightgbm等传统模型进行集成，是否有提升？ 值得尝试。

## 致谢
感谢老师、助教 仔细地批改作业。

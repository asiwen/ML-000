{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载 line_profiler 扩增, 执行魔术命令lprun分析代码:\n",
    "```jupyter\n",
    "%load_ext line_profiler\n",
    "%lprun\n",
    "```\n",
    "G20200616010153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述\n",
    "本练习尝试了4种方法对v1版本进行优化，并利用line_profiler, timeit工具进行测试对比。\n",
    "\n",
    "| vx  |line_profiler              |timeit   | remark  |   |\n",
    "|---|---|---|---|---|\n",
    "|target_mean_v1  | 33.85s         |17.2s   | 优化前  |   |\n",
    "|target_mean_v2   |2.04s / 17+ up |864ms / 19+ up   | v1基础上，分组循环改进，减少重复计算   |   |\n",
    "|target_mean_v3   |0.039s / 867+up|7.76ms / 2216+ up   | v2基础上，去dataframe检索  |   |\n",
    "|target_mean_v4   |0.031s / 1000+ |12.4ms / 1387+ up   | v3基础上，分组统计，字典优化 |   |\n",
    "|target_mean_v5   |  -- | 877us / 21000+up   |v3基础上，cython改进   |   |\n",
    "\n",
    "小结：\n",
    "* pandas的检索实在太慢\n",
    "* defaultdict的访问性能 已经接近数组的随机存取。\n",
    "* 用C/C++中的静态类型来优化python中的动态类型，性能大幅度提速 target_mean_v5\n",
    "\n",
    "遗留问题：\n",
    "line_profiler, timeit两种不同工具的测试结果不相同？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "y = np.random.randint(2, size=(5000, 1))\n",
    "x = np.random.randint(10, size=(5000, 1))\n",
    "data = pd.DataFrame(np.concatenate([y, x], axis=1), columns=['y', 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_mean_v1(data, y_name, x_name):\n",
    "    result = np.zeros(data.shape[0])\n",
    "    for i in range(data.shape[0]):\n",
    "        groupby_result = data[data.index != i].groupby([x_name], as_index=False).agg(['mean', 'count'])\n",
    "        result[i] = groupby_result.loc[groupby_result.index == data.loc[i, x_name], (y_name, 'mean')]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 38.3201 s\n",
       "File: <ipython-input-6-1e10119a1d07>\n",
       "Function: target_mean_v1 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def target_mean_v1(data, y_name, x_name):\n",
       "     2         1        243.0    243.0      0.0      result = np.zeros(data.shape[0])\n",
       "     3      5001       6766.0      1.4      0.0      for i in range(data.shape[0]):\n",
       "     4      5000   32304996.0   6461.0     84.3          groupby_result = data[data.index != i].groupby([x_name], as_index=False).agg(['mean', 'count'])\n",
       "     5      5000    6008104.0   1201.6     15.7          result[i] = groupby_result.loc[groupby_result.index == data.loc[i, x_name], (y_name, 'mean')]\n",
       "     6         1          0.0      0.0      0.0      return result"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f target_mean_v1 target_mean_v1(data, 'y', 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target_mean_v2\n",
    "target_mean_v1 中为每条记录求mean,count，会导致其余数据多次sum, count。\n",
    "\n",
    "改进方法：\n",
    "* 先对所有数据分组，同时计算该分组类的count，sum.\n",
    "* 在依次处理每条记录：找到该记录对应组，减去记录本身值后求mean。\n",
    "\n",
    "改进前时间复杂度： O(n*n), 改进后：O(n)，应该要快不少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def target_mean_v2(data, y_name, x_name):\n",
    "    grp_sum = defaultdict(lambda: 0)\n",
    "    grp_cnt = defaultdict(lambda: 0)\n",
    "    nrow = data.shape[0]\n",
    "    result = np.zeros(nrow)\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    for rx in range(nrow):\n",
    "        row = data.iloc[rx]\n",
    "        x_v, y_v = row[x_name], row[y_name]\n",
    "        grp_sum[x_v] += y_v\n",
    "        grp_cnt[x_v] += 1\n",
    "        \n",
    "        total_sum += y_v\n",
    "        total_count += 1\n",
    "        \n",
    "    total_mean = total_sum / total_count\n",
    "    \n",
    "    for rx in range(nrow):\n",
    "        row = data.iloc[rx]\n",
    "        x_v, y_v = row[x_name], row[y_name]\n",
    "        g = grp_cnt[x_v]\n",
    "        if g == 1:\n",
    "            result[rx] = total_mean\n",
    "        else:\n",
    "            result[rx] = (grp_sum[x_v] - y_v)/(g - 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 2.04039 s\n",
       "File: <ipython-input-36-c2315dfff126>\n",
       "Function: target_mean_v2 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def target_mean_v2(data, y_name, x_name):\n",
       "     2         1          4.0      4.0      0.0      grp_sum = defaultdict(lambda: 0)\n",
       "     3         1          1.0      1.0      0.0      grp_cnt = defaultdict(lambda: 0)\n",
       "     4         1         21.0     21.0      0.0      nrow = data.shape[0]\n",
       "     5         1         23.0     23.0      0.0      result = np.zeros(nrow)\n",
       "     6         1          1.0      1.0      0.0      total_sum = 0\n",
       "     7         1          1.0      1.0      0.0      total_count = 0\n",
       "     8      5001       3033.0      0.6      0.1      for rx in range(nrow):\n",
       "     9      5000     895742.0    179.1     43.9          row = data.iloc[rx]\n",
       "    10      5000     121521.0     24.3      6.0          x_v, y_v = row[x_name], row[y_name]\n",
       "    11      5000       8282.0      1.7      0.4          grp_sum[x_v] += y_v\n",
       "    12      5000       4143.0      0.8      0.2          grp_cnt[x_v] += 1\n",
       "    13                                                   \n",
       "    14      5000       3585.0      0.7      0.2          total_sum += y_v\n",
       "    15      5000       3038.0      0.6      0.1          total_count += 1\n",
       "    16                                                   \n",
       "    17         1          2.0      2.0      0.0      total_mean = total_sum / total_count\n",
       "    18                                               \n",
       "    19      5001       3161.0      0.6      0.2      for rx in range(nrow):\n",
       "    20      5000     862147.0    172.4     42.3          row = data.iloc[rx]\n",
       "    21      5000     117006.0     23.4      5.7          x_v, y_v = row[x_name], row[y_name]\n",
       "    22      5000       5336.0      1.1      0.3          g = grp_cnt[x_v]\n",
       "    23      5000       3208.0      0.6      0.2          if g == 1:\n",
       "    24                                                       result[rx] = total_mean\n",
       "    25                                                   else:\n",
       "    26      5000      10135.0      2.0      0.5              result[rx] = (grp_sum[x_v] - y_v)/(g - 1)\n",
       "    27         1          0.0      0.0      0.0      return result"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f target_mean_v2 target_mean_v2(data, 'y', 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target_encoding_v3\n",
    "target_encoding_v2 比 v1快约17倍。 \n",
    "根据v2的trick分析知： data.iloc 语句还有待优化: 即采用DataFrame原生的元素检索方式性能非得低下，两处循环中DataFrame检索消耗占到了98%。\n",
    "\n",
    "利用DataFrame的values属性可以获得DataFrame内部数据的Numpy.narray二位数组表示形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def target_mean_v3(data, y_name, x_name):\n",
    "    grp_sum = defaultdict(lambda: 0)\n",
    "    grp_cnt = defaultdict(lambda: 0)\n",
    "    nrow = data.shape[0]\n",
    "    result = np.zeros(nrow)\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    x = data[x_name].values\n",
    "    y = data[y_name].values\n",
    "    \n",
    "    xy = zip(x, y)\n",
    "    \n",
    "    for x_v, y_v in xy:\n",
    "        grp_sum[x_v] += y_v\n",
    "        grp_cnt[x_v] += 1\n",
    "        \n",
    "        total_sum += y_v\n",
    "        total_count += 1\n",
    "        \n",
    "    total_mean = total_sum / total_count\n",
    "    \n",
    "    return np.array([total_mean if grp_cnt[x_v] <= 1 else (grp_sum[x_v] - y_v)/(grp_cnt[x_v] - 1) for x_v, y_v in zip(x, y) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.039221 s\n",
       "File: <ipython-input-59-6ce07509522c>\n",
       "Function: target_mean_v3 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def target_mean_v3(data, y_name, x_name):\n",
       "     2         1          5.0      5.0      0.0      grp_sum = defaultdict(lambda: 0)\n",
       "     3         1          3.0      3.0      0.0      grp_cnt = defaultdict(lambda: 0)\n",
       "     4         1         19.0     19.0      0.0      nrow = data.shape[0]\n",
       "     5         1         18.0     18.0      0.0      result = np.zeros(nrow)\n",
       "     6         1          2.0      2.0      0.0      total_sum = 0\n",
       "     7         1          2.0      2.0      0.0      total_count = 0\n",
       "     8                                               \n",
       "     9         1         60.0     60.0      0.2      x = data[x_name].values\n",
       "    10         1         25.0     25.0      0.1      y = data[y_name].values\n",
       "    11                                               \n",
       "    12         1          4.0      4.0      0.0      xy = zip(x, y)\n",
       "    13                                               \n",
       "    14      5001       7247.0      1.4     18.5      for x_v, y_v in xy:\n",
       "    15      5000       7595.0      1.5     19.4          grp_sum[x_v] += y_v\n",
       "    16      5000       6205.0      1.2     15.8          grp_cnt[x_v] += 1\n",
       "    17                                                   \n",
       "    18      5000       6491.0      1.3     16.5          total_sum += y_v\n",
       "    19      5000       6328.0      1.3     16.1          total_count += 1\n",
       "    20                                                   \n",
       "    21         1          4.0      4.0      0.0      total_mean = total_sum / total_count\n",
       "    22                                               \n",
       "    23         1       5213.0   5213.0     13.3      return np.array([total_mean if grp_cnt[x_v] <= 1 else (grp_sum[x_v] - y_v)/(grp_cnt[x_v] - 1) for x_v, y_v in zip(x, y) ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f target_mean_v3 target_mean_v3(data, 'y', 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target_encoding_v4\n",
    "\n",
    "v3 相比 v1提升了 1100倍（33 / 0.03）。从trick结果来看，如果不采用C语言等其他技术，那么尝试用对字典的查找进行优化。例如，采用数组的来存放分组（用下标来标识组key）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def target_mean_v4(data, y_name, x_name):\n",
    "    nrow = data.shape[0]\n",
    "    grp_sum = np.zeros(nrow)\n",
    "    grp_cnt = np.zeros(nrow)\n",
    "    result = np.zeros(nrow)\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    x = data[x_name].values\n",
    "    y = data[y_name].values\n",
    "    \n",
    "    xy = zip(x, y)\n",
    "    \n",
    "    for x_v, y_v in xy:\n",
    "        grp_sum[x_v] += y_v\n",
    "        grp_cnt[x_v] += 1\n",
    "        \n",
    "        total_sum += y_v\n",
    "        total_count += 1\n",
    "        \n",
    "    total_mean = total_sum / total_count\n",
    "    \n",
    "    return np.array([total_mean if grp_cnt[x_v] <= 1 else (grp_sum[x_v] - y_v)/(grp_cnt[x_v] - 1) for x_v, y_v in zip(x, y) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.031409 s\n",
       "File: <ipython-input-64-10b9a7076fd7>\n",
       "Function: target_mean_v4 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def target_mean_v4(data, y_name, x_name):\n",
       "     2         1         16.0     16.0      0.1      nrow = data.shape[0]\n",
       "     3         1        100.0    100.0      0.3      grp_sum = np.zeros(nrow)\n",
       "     4         1         71.0     71.0      0.2      grp_cnt = np.zeros(nrow)\n",
       "     5         1         93.0     93.0      0.3      result = np.zeros(nrow)\n",
       "     6         1          1.0      1.0      0.0      total_sum = 0\n",
       "     7         1          1.0      1.0      0.0      total_count = 0\n",
       "     8                                               \n",
       "     9         1         50.0     50.0      0.2      x = data[x_name].values\n",
       "    10         1         18.0     18.0      0.1      y = data[y_name].values\n",
       "    11                                               \n",
       "    12         1          2.0      2.0      0.0      xy = zip(x, y)\n",
       "    13                                               \n",
       "    14      5001       4070.0      0.8     13.0      for x_v, y_v in xy:\n",
       "    15      5000       5408.0      1.1     17.2          grp_sum[x_v] += y_v\n",
       "    16      5000       6068.0      1.2     19.3          grp_cnt[x_v] += 1\n",
       "    17                                                   \n",
       "    18      5000       3588.0      0.7     11.4          total_sum += y_v\n",
       "    19      5000       3379.0      0.7     10.8          total_count += 1\n",
       "    20                                                   \n",
       "    21         1          4.0      4.0      0.0      total_mean = total_sum / total_count\n",
       "    22                                               \n",
       "    23         1       8540.0   8540.0     27.2      return np.array([total_mean if grp_cnt[x_v] <= 1 else (grp_sum[x_v] - y_v)/(grp_cnt[x_v] - 1) for x_v, y_v in zip(x, y) ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f target_mean_v4 target_mean_v4(data, 'y', 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target_encoding_v5\n",
    "v4与v3相比，性能上没有显著提升。 说明 字典的查找并非瓶颈。 这么看来应该要优化内存的读写了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as cnp\n",
    "from collections import defaultdict\n",
    "from libc.string cimport memset\n",
    "\n",
    "def default_value():\n",
    "    return 0\n",
    "\n",
    "cpdef target_mean_v5(cnp.ndarray[long] x, cnp.ndarray[double] y, cnp.ndarray[double] result, const int nlabels):\n",
    "    n = x.shape[0]\n",
    "    #sum_dict = defaultdict(default_value)\n",
    "    #cnt_dict = defaultdict(default_value)\n",
    "    cdef double sum_dict[nlabels]\n",
    "    cdef long cnt_dict[nlabels]\n",
    "    cdef double total = 0\n",
    "    cdef long cnt = 0\n",
    "    \n",
    "    memset(sum_dict, 0, nlabels*sizeof(double))\n",
    "    memset(cnt_dict, 0, nlabels*sizeof(long))\n",
    "    \n",
    "    for i in range(n):\n",
    "        xv, yv = x[i], y[i]\n",
    "        sum_dict[xv] += yv\n",
    "        cnt_dict[xv] +=1\n",
    "        total += yv\n",
    "        cnt +=1\n",
    "        \n",
    "    total_mean = total / cnt\n",
    "    for i in range(n):\n",
    "        xv, yv = x[i], y[i]\n",
    "        c = cnt_dict[xv]\n",
    "        result[i] = total_mean if c == 1 else (sum_dict[xv] - yv)/(c-1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = target_mean_v1(data, 'y', 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.8 s ± 1.27 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "r=target_mean_v1(data, 'y', 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838 ms ± 35.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "r2=target_mean_v2(data, 'y', 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.16 ms ± 15.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "r3=target_mean_v3(data, 'y', 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4 ms ± 76.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "r4=target_mean_v4(data, 'y', 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877 µs ± 33.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "r5 = target_mean_v5(data['x'].to_numpy(np.int), data['y'].to_numpy(np.float64), np.zeros(data.shape[0], dtype=np.float64), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 = target_mean_v2(data, 'y', 'x')\n",
    "r3 = target_mean_v3(data, 'y', 'x')\n",
    "# r4 = target_mean_v4(data, 'y', 'x')\n",
    "r5 = target_mean_v5(data['x'].to_numpy(np.int), data['y'].to_numpy(np.float64), np.zeros(data.shape[0], dtype=np.float64), 10)\n",
    "np.linalg.norm(r5 - r3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
